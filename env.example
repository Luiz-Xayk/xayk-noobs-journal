# Xayk Noob's Journal - Configuration
# Copy this file to .env and configure your settings

# LLM Provider: "auto", "ollama", or "gemini"
# auto = tries Ollama first (local, no limits), then Gemini
# ollama = local LLM (requires Ollama installed, no API limits)
# gemini = cloud LLM (requires API key, has rate limits)
LLM_PROVIDER=auto

# Google Gemini API Key (optional if using Ollama)
# Get your free key at: https://aistudio.google.com/app/apikey
GEMINI_API_KEY=your_gemini_api_key_here

# Mode: "passive" (no spoilers) or "active" (with hints)
MODE=passive
